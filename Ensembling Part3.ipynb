{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d98e177",
   "metadata": {},
   "source": [
    "# Voting :\n",
    "\n",
    "A voting ensemble, also known as a voting classifier or majority voting, is a machine learning technique that combines the predictions of multiple indvidual classifiers to make a final prediction. It isa popular method for improving the accuracy and robustness of classification.\n",
    "\n",
    "the idea behind a voting ensemble is that by aggregating the predictions of multiple models, the ensemble can benefit from the diversity of opinions and capture different aspects of the data, leading to more accurate predictions. The ensemble combines the individual predictions through a voting scheme, where each model's prediction is treated as vote, and the majority prediction is chosen as the final output.\n",
    "\n",
    "There are two main types of voting ensembles: hard voting and soft voting\n",
    "\n",
    "(1). Hard Voting : In hard voting ,each individual classifier in the ensemble predicts a class label, and the class label that recievs the majority of votes is selected as the final prediction.For example,If there are three classifiers inthe ensemble, and two of them predict class A while one predict classB , the final prediction woould be class A.\n",
    "\n",
    "(2). Soft Voting : In soft voting ,instead of predicting just the class labels, each individual classifier assigns probabilities is selected as the final prediction.This method takes into account the confidence of each classifier's prediction.\n",
    "\n",
    "Voting ensembles can be implemented using different types, such as decision trees, support vetor machines,logistic regression, or neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970a6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c2e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a synthetic classifier dataset\n",
    "X,y=make_classification(n_samples=1000,n_features=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7538a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into traing and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9688262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize individual classifier\n",
    "tree_clf=DecisionTreeClassifier(random_state=42)\n",
    "log_reg=LogisticRegression(random_state=42)\n",
    "svm_clf=SVC(probability=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c80f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the voting ensemble\n",
    "voting_clf=VotingClassifier(\n",
    "    estimators=[('tree',tree_clf),('log_reg',log_reg),('svm',svm_clf)],\n",
    "    voting='hard' # use 'hard'for hard voting or 'soft' for soft voting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b40c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the ensemble\n",
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d17270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble Accuracy 0.835\n"
     ]
    }
   ],
   "source": [
    "#Make prediction on the testing set\n",
    "y_pred=voting_clf.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"Voting Ensemble Accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "In which scenerio I can use voting ensemble?\n",
    "\n",
    "Voting ensembles can be useful in various scenerio whre you have multiple classifiers and want to combine their predictions to make a final desicion.\n",
    "\n",
    "(1). Model diversity: When you have different classifiers that capture different aspects of the data or have different strengths and weakness, a voting ensemble can help leverage their diversity.For example, if you have a decision tree classifier, alogistic regression classifier and support vector machine,combining their prediction through a voting ensemble can help capture differnt patterns and improve overall performance.\n",
    "    \n",
    "(2). Robustness: Voting ensembles can improve robustness by reducing the impact of individual classifier errors. if some classiifers in the ensemble make incoorect preidictions due to noise or outliers i the data, the ensemble can still provide accurate results by relying on the majority vote. This can be particularly useful in scenerios where the individual classifiers may have high variance or are sensitive to specific types of errors.\n",
    "    \n",
    "(3). Model Selection: Voting ensembles can simplify the model selection process by incorporating multiple models without extensive hyperparameter tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
