{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80163ec6",
   "metadata": {},
   "source": [
    "# Boosting ==>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c00028",
   "metadata": {},
   "source": [
    "# There are several types of boosting algorithms commonly used in ensemble learning.Some of the popular ones include:\n",
    "\n",
    "(1). AdaBoost(Adaptive Boosting):\n",
    "AdaBoost is one of the earliest and most well-known boosting algorithms.It assigns higher weights to misclassified instances and focuses on those instances during subsequent iterations.It sequentially trains a series of weak learners and combines their predictions to form the final ensemble.ADaboost is primarily used for binary classification.\n",
    "\n",
    "(2). Gradient Boosting: Gradient Boosting an ensemble of weak leaners in a stage-wise manner.Each subsequent model is trained to correct the mistakes made by the previous models by fitiing the negative gradient of a loss function.Gradient Boosting can handle both classification and regression  tasks and is oftenused with decision trees as base learners.Examples of gradient boosting algorithms include XGboost,Lightboost and CatBoost.\n",
    "\n",
    "(3). XGBoost(Extreme Gradient Boosting): XGBoost is an optimised implementation of gradient boosting that offers several enhancements, including parallel processing,regularization techniques and handling missing values.It uses a combination of tree-based models and linear models for boosting, which allows it to capture both linear and non-linear relationships in the data efficiently.\n",
    "\n",
    "(4). LightGBM: LightGBM is another gradient boosting framework that focuseson achieving faster training speed and lower memory usage.It uses a novel tree-growing algorithm called \"Gradient-based One-Side Sampling\" (GOSS) to select the most informative instances for building decision trees.\n",
    "\n",
    "(5). CatBoost: CatBoost is a gradient boosting algorithm that is designed to handle categorical features directly withoout the need for extensive data preprocessing.It incorporates an innovative method to handle categorical variables , which includes applying a combination of ordered boosting, random permutations, and symmetric tress.\n",
    "\n",
    "(6). Stochastic Gradient Boosting: Stochastic Gradient boosting intoduces randomness into the boosting process by subsampling the training data or features at each iteration.It helps to reduce overfitting and can improve the model's generalization ability, especially when dealing with large datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ee2cf",
   "metadata": {},
   "source": [
    "# How i decide which boosting algorithm type I have to use in which scenerio?\n",
    "\n",
    "Deciding which boosting algorithm to use in a specific scenerio depends on several factors. Here are some guidlines to help youo make a decision.\n",
    "\n",
    "(1). Problem type: consider whether you are working on a classification or regression problem.Some boosting algorithms are specifically designed for binary classification tasks,while others can handle both classification and regression. For example, Adaboost is primarily used for binary classification, while XGboost and LightGBM are versatile and can be used for both classification and regression tasks.\n",
    " \n",
    "(2). Dataset size: take into account the size of your dataset. If you have a large dataset, algorithm like LightGBM or CatBoost that are optimised for faster training speed and lower memory usage can be beneficial. Thy utilize techniques such as data subsamping or feature subsampling to handle large datasets more efficiently.\n",
    "    \n",
    "(3).Dataset complexity: consider the complexity of your dataset and the relationships within it.If your dataset contains a mix categorical and numerical features. CatBoost might be a good choice as it handles categorical variables directly withoutm the need for entensive preprocessing.On the other hand, if you have dataset with complex patterns and nonlinear relationships, algorithms like XGBoost or LightGBM,which usea combination of tree based models and linear models, may be more suitable.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a2fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef627ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b20228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a synthetic clasification dataset\n",
    "X,y=make_classification(n_samples=1000,n_features=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defbde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea4fff32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=100, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and training and AdaBoost classifier\n",
    "adaboost= AdaBoostClassifier(n_estimators=100,random_state=42)\n",
    "adaboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a807527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating and traing on XGBoost classifier\n",
    "xgboost=XGBClassifier(n_estimators=100,random_state=42)\n",
    "xgboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4474c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set for Adaboost\n",
    "y_pred_adaboost=adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08591589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set for XGBoost\n",
    "y_pred_xgboost=xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da961c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of AdaBoost\n",
    "accuracy_adaboost=accuracy_score(y_test,y_pred_adaboost)\n",
    "print(\"AdaBoost Accuracy:\",accuracy_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa61328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of XGBoost\n",
    "accuracy_xgboost=accuracy_score(y_test,y_pred_xgboost)\n",
    "print(\"XGBoost Accuracy:\",accuracy_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32dbc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04b6bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libarries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc64f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a synthetic clasification dataset\n",
    "X,y=make_classification(n_samples=1000,n_features=10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72566a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6979d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gb_classifier=GradientBoostingClassifier(n_estimators=100,random_state=42)\n",
    "gb_classifier.fit(X_train,y_train)\n",
    "y_pred_gb=gb_classifier.predict(X_test)\n",
    "accuracy_gb=accuracy_score(y_test,y_pred_gb)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\",accuracy_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7ac63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 388, number of negative: 412\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.485000 -> initscore=-0.060018\n",
      "[LightGBM] [Info] Start training from score -0.060018\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Classifier Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Classifier\n",
    "lgb_classifier=LGBMClassifier(n_estimators=100,random_state=42)\n",
    "lgb_classifier.fit(X_train,y_train)\n",
    "y_pred_lgb=lgb_classifier.predict(X_test)\n",
    "accuracy_lgb=accuracy_score(y_test,y_pred_lgb)\n",
    "print(\"LightGBM Classifier Accuracy:\",accuracy_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e3ed476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classifier Accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Classifier\n",
    "cat_classifier=CatBoostClassifier(n_estimators=100,random_state=42,verbose=0)\n",
    "cat_classifier.fit(X_train,y_train)\n",
    "y_pred_cat=cat_classifier.predict(X_test)\n",
    "accuracy_cat=accuracy_score(y_test,y_pred_cat)\n",
    "print(\"CatBoost Classifier Accuracy:\",accuracy_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd7c4625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Boosting Classifier Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Boosting Classifier\n",
    "stoch_gb_classifier=HistGradientBoostingClassifier(max_iter=100,random_state=42)\n",
    "stoch_gb_classifier.fit(X_train,y_train)\n",
    "y_pred_stoch_gb=stoch_gb_classifier.predict(X_test)\n",
    "accuracy_stoch_gb=accuracy_score(y_test,y_pred_stoch_gb)\n",
    "print(\"Stochastic Gradient Boosting Classifier Accuracy:\",accuracy_stoch_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad5f080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "gb_regressor=GradientBoostingRegressor(n_estimators=100,random_state=42)\n",
    "gb_regressor.fit(X_train,y_train)\n",
    "y_pred_gb_regressor=gb_regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5e841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
